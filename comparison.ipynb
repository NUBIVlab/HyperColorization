{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dont own the codes for SASSI, If you get permission from Vishwanath Saragadam (https://vishwa91.github.io/), I can share the codes for SASSI and SASSI_testing (my wrapper function for SASSI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and Modules\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "nb_dir = os.getcwd()\n",
    "sys.path.insert(0,nb_dir+'/SASSI')\n",
    "import aux_funcs.noise as noise\n",
    "import aux_funcs.visualization as vis\n",
    "import aux_funcs.data_import as data\n",
    "import aux_funcs.colorization as clr\n",
    "import aux_funcs.spectral_dimensionality as dim\n",
    "import aux_funcs.metrics as qm\n",
    "import aux_funcs.initialization as init\n",
    "import aux_funcs.comparioson_helpers as comp\n",
    "from SASSI.demo import SASSI_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lams, hpim) = data.importer.BearAndFruit_low_res()\n",
    "l,h,w = hpim.shape\n",
    "print(l,h,w)\n",
    "vis.draw_hpim(hpim, draw=True, lams = lams, method='1931')\n",
    "sd = dim.SpectralDim()\n",
    "sd.loadSpectralBasis('data/spectral_basis_data_400-10-700.npy')\n",
    "metrics, hib, _ = qm.getQualityMetrics() # hib stands for higher is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_methods(hpim: np.ndarray,lams: np.ndarray,sd:dim.SpectralDim,metrics:dict,sampling_ratio:float=0.03,\n",
    "                    zoom_region:tuple=None,interest_point1:tuple=None,interest_point2:tuple=None,data_name:str=None):\n",
    "    base_path = os.path.join('results', 'comparison', data_name)\n",
    "    os.mkdir(base_path)\n",
    "    vis_method = '1931'\n",
    "    tick_font_size = 12\n",
    "    label_font_size = 14\n",
    "    pad = 0.1\n",
    "    exposure_time_scale = hpim.shape[0] / 31\n",
    "    exposure_times = [exposure_time_scale*1e-3, exposure_time_scale*1e-4, exposure_time_scale*1e-5]\n",
    "    gray = np.sum(hpim, axis=0, keepdims=True)\n",
    "    rgb = vis.draw_hpim(hpim, lams, False, vis_method)\n",
    "    result_dict = {}\n",
    "    result_dict['cao'] = {}\n",
    "    result_dict['sassi'] = {}\n",
    "    result_dict['hc'] = {}\n",
    "    for key in result_dict.keys():\n",
    "        result_dict[key]['PSNR'] = []\n",
    "        result_dict[key]['EMD'] = []\n",
    "        result_dict[key]['GFC'] = []\n",
    "        result_dict[key]['SSV'] = []\n",
    "        result_dict[key]['time'] = 0\n",
    "    result_dict['exposure_times'] = exposure_times\n",
    "    for exposure_time in exposure_times:\n",
    "        current_path = os.path.join(base_path, '{:.0e}'.format(exposure_time))\n",
    "        os.mkdir(current_path)\n",
    "        hpim_n = noise.addPoissonNoise(hpim, exposure_time)\n",
    "        #hpim_n = noise.addGaussianNoise(hpim_n, 0, 0.01)\n",
    "        t0 = time.time()\n",
    "        hc_result = comp.hyperColorizationWrapper(gray, hpim_n, lams, sd, sampling_ratio, False)\n",
    "        t1 = time.time()\n",
    "        cao_result = comp.Cao2015Wrapper(hpim_n, rgb, sampling_ratio)\n",
    "        t2 = time.time()\n",
    "        sassi_result, _ = SASSI_testing(hpim, hpim_n, lams, sampling_ratio)\n",
    "        sassi_result *= np.sum(hpim) / np.sum(sassi_result)\n",
    "        t3 = time.time()\n",
    "        vis.save_hpim(os.path.join(current_path, 'hc.png'), hc_result, lams, method=vis_method)\n",
    "        vis.save_hpim(os.path.join(current_path, 'sassi.png'), sassi_result, lams, method=vis_method)\n",
    "        vis.save_hpim(os.path.join(current_path, 'cao.png'), cao_result, lams, method=vis_method)\n",
    "        for key in result_dict['cao'].keys():\n",
    "            if key == 'time':\n",
    "                result_dict['cao']['time'] += (t2-t1)/len(exposure_times)\n",
    "                result_dict['sassi']['time'] += (t3-t2)/len(exposure_times)\n",
    "                result_dict['hc']['time'] += (t1-t0)/len(exposure_times)\n",
    "                continue\n",
    "            result_dict['cao'][key].append(metrics[key](hpim, cao_result))\n",
    "            result_dict['sassi'][key].append(metrics[key](hpim, sassi_result))\n",
    "            result_dict['hc'][key].append(metrics[key](hpim, hc_result))    \n",
    "        if zoom_region != None:\n",
    "            top_left = zoom_region[0]\n",
    "            bottom_right = zoom_region[1]\n",
    "            hc_zoomed = hc_result[:, top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "            sassi_zoomed = sassi_result[:, top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "            cao_zoomed = cao_result[:, top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "            vis.save_hpim(os.path.join(current_path, 'hc_zoomed.png'), hc_zoomed, lams, method=vis_method)\n",
    "            vis.save_hpim(os.path.join(current_path, 'sassi_zoomed.png'), sassi_zoomed, lams, method=vis_method)\n",
    "            vis.save_hpim(os.path.join(current_path, 'cao_zoomed.png'), cao_zoomed, lams, method=vis_method)\n",
    "        if interest_point1 != None:\n",
    "            gt_spectral_curve = hpim[:, interest_point1[1], interest_point1[0]]\n",
    "            hc_spectral_curve = hc_result[:, interest_point1[1], interest_point1[0]]\n",
    "            sassi_spectral_curve = sassi_result[:, interest_point1[1], interest_point1[0]]\n",
    "            cao_spectral_curve = cao_result[:, interest_point1[1], interest_point1[0]]\n",
    "            fig = plt.figure('line', figsize=(10,6))\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.plot(lams, gt_spectral_curve, label='Ground Truth', color='black', linewidth = '3')\n",
    "            ax.plot(lams, hc_spectral_curve, label='HC', alpha = 1.0)\n",
    "            ax.plot(lams, sassi_spectral_curve, label='SASSI', alpha = 0.8)\n",
    "            ax.plot(lams, cao_spectral_curve, label='Cao et al.', alpha = 0.6)\n",
    "            #plt.legend()\n",
    "            ax.set_xlabel('λ', fontsize=label_font_size)\n",
    "            ax.set_ylabel('Intensity', fontsize=label_font_size)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=tick_font_size)\n",
    "            fig.savefig(os.path.join(current_path, 'spectral_curve1.png'), bbox_inches='tight', pad_inches=pad)\n",
    "            plt.close()\n",
    "        if interest_point2 != None:\n",
    "            gt_spectral_curve = hpim[:, interest_point2[1], interest_point2[0]]\n",
    "            hc_spectral_curve = hc_result[:, interest_point2[1], interest_point2[0]]\n",
    "            sassi_spectral_curve = sassi_result[:, interest_point2[1], interest_point2[0]]\n",
    "            cao_spectral_curve = cao_result[:, interest_point2[1], interest_point2[0]]\n",
    "            fig = plt.figure('line', figsize=(10,6))\n",
    "            ax = fig.add_subplot(111)\n",
    "            line1 = ax.plot(lams, gt_spectral_curve, label='Ground Truth', color='black', linewidth = '3')\n",
    "            line2 =ax.plot(lams, hc_spectral_curve, label='HC', alpha = 1.0)\n",
    "            line3 =ax.plot(lams, sassi_spectral_curve, label='SASSI', alpha = 0.8)\n",
    "            line4 =ax.plot(lams, cao_spectral_curve, label='Cao et al.', alpha = 0.6)\n",
    "            ax.set_xlabel('λ', fontsize=label_font_size)\n",
    "            ax.set_ylabel('Intensity', fontsize=label_font_size)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=tick_font_size)\n",
    "            handles,labels = ax.get_legend_handles_labels()\n",
    "            fig.savefig(os.path.join(current_path, 'spectral_curve2.png'), bbox_inches='tight', pad_inches=pad)\n",
    "            plt.close()\n",
    "            fig_legend = plt.figure(figsize=(2,2))\n",
    "            axi = fig_legend.add_subplot(111)            \n",
    "            fig_legend.legend(handles, labels, loc='center', scatterpoints = 1)\n",
    "            axi.xaxis.set_visible(False)\n",
    "            axi.yaxis.set_visible(False)\n",
    "            fig_legend.canvas.draw()\n",
    "            fig_legend.savefig(os.path.join(current_path, 'legend.png'), bbox_inches='tight', pad_inches=pad)\n",
    "            plt.close()\n",
    "        print('{} Exposure time {:.0e} finished'.format(data_name, exposure_time))\n",
    "        print('PSNR: HC {:.2f}, SASSI {:.2f}, Cao {:.2f}'.format(result_dict['hc']['PSNR'][-1], result_dict['sassi']['PSNR'][-1], result_dict['cao']['PSNR'][-1]))\n",
    "    with open(os.path.join(base_path, 'results.pkl'), 'wb') as f:\n",
    "        pickle.dump(result_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_methods(hpim, lams, sd, metrics, 0.03, ((69,149),(154,216)), (362,300), (86,302), 'ICVL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkPerformanceNumbers(data_name: str, metric: str):\n",
    "    with open(os.path.join('results','comparison', data_name, 'results.pkl'), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        print('Average Run time: HC {:.2f}, SASSI {:.2f}, Cao {:.2f}'.format(data['hc']['time'], data['sassi']['time'], data['cao']['time']))\n",
    "        print('Exposure Time:{:.2e} {}: HC {:.2e}, SASSI {:.2e}, Cao {:.2e}'.format(data['exposure_times'][0],metric,data['hc'][metric][0], data['sassi'][metric][0], data['cao'][metric][0]))\n",
    "        print('Exposure Time:{:.2e} {}: HC {:.2e}, SASSI {:.2e}, Cao {:.2e}'.format(data['exposure_times'][1],metric,data['hc'][metric][1], data['sassi'][metric][1], data['cao'][metric][1]))\n",
    "        print('Exposure Time:{:.2e} {}: HC {:.2e}, SASSI {:.2e}, Cao {:.2e}'.format(data['exposure_times'][2],metric,data['hc'][metric][2], data['sassi'][metric][2], data['cao'][metric][2]))\n",
    "    return\n",
    "checkPerformanceNumbers('bear_and_fruit', 'EMD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_methods_over_dataset(data_dict, metrics, sampling_ratio = 0.03):\n",
    "    for key in data_dict.keys():\n",
    "        if key == 'bear_and_fruit':\n",
    "            if os.path.exists(os.path.join('results', 'comparison', key)):\n",
    "                continue\n",
    "            lams, hpim = data.importer.BearAndFruit()\n",
    "            sd = dim.SpectralDim()\n",
    "            sd.loadSpectralBasis('data/spectral_basis_data_400-10-700.npy')\n",
    "            compare_methods(hpim, lams, sd, metrics, sampling_ratio, data_name=key)\n",
    "        if key == 'Harvard':\n",
    "            sd = dim.SpectralDim()\n",
    "            sd.loadSpectralBasis('data/spectral_basis_data_420-10-720.npy')\n",
    "            if not os.path.exists(os.path.join('results', 'comparison', key)):\n",
    "                os.mkdir(os.path.join('results', 'comparison', key))\n",
    "            for entry in data_dict[key]:\n",
    "                if os.path.exists(os.path.join('results', 'comparison', key, str(entry))):\n",
    "                    continue\n",
    "                lams, hpim = data.importer.load_Harvard_img(entry)\n",
    "                compare_methods(hpim, lams, sd, metrics, sampling_ratio, data_name=os.path.join(key, str(entry)))\n",
    "        if key == 'CAVE':\n",
    "            sd = dim.SpectralDim()\n",
    "            sd.loadSpectralBasis('data/spectral_basis_data_400-10-700.npy')\n",
    "            if not os.path.exists(os.path.join('results', 'comparison', key)):\n",
    "                os.mkdir(os.path.join('results', 'comparison', key))\n",
    "            for entry in data_dict[key]:\n",
    "                if os.path.exists(os.path.join('results', 'comparison', key, str(entry))):\n",
    "                    continue\n",
    "                lams, hpim = data.importer.load_CAVE_img(entry)\n",
    "                compare_methods(hpim, lams, sd, metrics, sampling_ratio, data_name=os.path.join(key, str(entry)))\n",
    "        if key == 'Kaist':\n",
    "            sd = dim.SpectralDim()\n",
    "            sd.loadSpectralBasis('data/spectral_basis_data_420-10-720.npy')\n",
    "            if not os.path.exists(os.path.join('results', 'comparison', key)):\n",
    "                os.mkdir(os.path.join('results', 'comparison', key))\n",
    "            for entry in data_dict[key]:\n",
    "                if os.path.exists(os.path.join('results', 'comparison', key, str(entry))):\n",
    "                    continue\n",
    "                lams, hpim = data.importer.load_KAIST_img(entry)\n",
    "                compare_methods(hpim, lams, sd, metrics, sampling_ratio, data_name=os.path.join(key, str(entry)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'bear_and_fruit': [0],\n",
    "    'Harvard': [0, 26, 44, 48, 49],\n",
    "    'Kaist': [2, 22, 26],\n",
    "    'CAVE': [0, 1, 5, 7]\n",
    "}\n",
    "compare_methods_over_dataset(data_dict, metrics, sampling_ratio = 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulatorHelper(accumulator:dict, pickleLoc:str, metric:str):\n",
    "     with open(pickleLoc, 'rb') as f:\n",
    "         d = pickle.load(f)\n",
    "         for key in accumulator.keys():\n",
    "            if key == 'time':\n",
    "                for key2 in accumulator[key].keys():\n",
    "                    accumulator[key][key2] += d[key2]['time']\n",
    "                continue\n",
    "            for i,entry in enumerate(accumulator[key]):\n",
    "                accumulator[key][i] += d[key][metric][i]\n",
    "        \n",
    "def checkPerformanceNumbersOverDataset(data_dict: dict, metric:str):\n",
    "    accumulator = {}\n",
    "    accumulator['hc'] = [0, 0, 0]\n",
    "    accumulator['sassi'] = [0, 0, 0]\n",
    "    accumulator['cao'] = [0, 0, 0]\n",
    "    accumulator['time'] = {'hc': 0, 'sassi': 0, 'cao': 0}\n",
    "    num_data = 0\n",
    "    for key in data_dict.keys():\n",
    "        if key == 'bear_and_fruit':\n",
    "            path_to_pickle = os.path.join('results', 'comparison', key, 'results.pkl')\n",
    "            accumulatorHelper(accumulator, path_to_pickle, metric)\n",
    "            num_data += 1\n",
    "        if key == 'Harvard':\n",
    "            for entry in data_dict[key]:\n",
    "                path_to_pickle = os.path.join('results', 'comparison', key, str(entry), 'results.pkl')\n",
    "                accumulatorHelper(accumulator, path_to_pickle, metric)\n",
    "                num_data += 1\n",
    "        if key == 'CAVE':\n",
    "            for entry in data_dict[key]:\n",
    "                path_to_pickle = os.path.join('results', 'comparison', key, str(entry), 'results.pkl')\n",
    "                accumulatorHelper(accumulator, path_to_pickle, metric)\n",
    "                num_data += 1\n",
    "        if key == 'Kaist':\n",
    "            for entry in data_dict[key]:\n",
    "                path_to_pickle = os.path.join('results', 'comparison', key, str(entry), 'results.pkl')\n",
    "                accumulatorHelper(accumulator, path_to_pickle, metric)\n",
    "                num_data += 1\n",
    "    print('Average ' + metric + ' score over ' + str(num_data) + ' hyperspectral images')\n",
    "    print('Exposure Time: 1e-3: HC {:.2e}, SASSI {:.2e}, Cao {:.2e}'.format(accumulator['hc'][0]/num_data, accumulator['sassi'][0]/num_data, accumulator['cao'][0]/num_data))\n",
    "    print('Exposure Time: 1e-4: HC {:.2e}, SASSI {:.2e}, Cao {:.2e}'.format(accumulator['hc'][1]/num_data, accumulator['sassi'][1]/num_data, accumulator['cao'][1]/num_data))\n",
    "    print('Exposure Time: 1e-5: HC {:.2e}, SASSI {:.2e}, Cao {:.2e}'.format(accumulator['hc'][2]/num_data, accumulator['sassi'][2]/num_data, accumulator['cao'][2]/num_data))\n",
    "    print('Average Run time: HC {:.2e}, SASSI {:.2e}, Cao {:.2e}'.format(accumulator['time']['hc']/num_data, accumulator['time']['sassi']/num_data, accumulator['time']['cao']/num_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkPerformanceNumbersOverDataset(data_dict, 'SSIM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_KAIST_recon_and_gt(recon_loc:str, gt_loc:str):\n",
    "    f = sp.io.loadmat(recon_loc)\n",
    "    x_recon = f['x_recon']\n",
    "    wvls2b = np.squeeze(f['wvls2b'])\n",
    "    x_recon = np.moveaxis(x_recon, -1, 0)\n",
    "    print('Reconstruction: ')\n",
    "    rgb_recon = vis.draw_hpim(x_recon, wvls2b, '1931')\n",
    "    plt.imsave('results/Kaist/KAIST_recon.png', rgb_recon)\n",
    "    plt.show()\n",
    "    f = sp.io.loadmat(gt_loc)\n",
    "    x_gt = f['img_hs']\n",
    "    x_gt = np.moveaxis(x_gt, -1, 0)\n",
    "    x_gt = x_gt / (np.max(x_gt))\n",
    "    print('Ground Truth: ')\n",
    "    rgb_gt = vis.draw_hpim(x_gt, wvls2b, '1931')\n",
    "    plt.imsave('results/Kaist/KAIST_gt.png', rgb_gt)\n",
    "    plt.show()\n",
    "    print('EMD: {:.4e}'.format(qm.EMD(x_gt, x_recon)))\n",
    "    print('SSIM: {:.4e}'.format(qm.SSIM(x_gt, x_recon)))\n",
    "    return x_gt, x_recon, wvls2b\n",
    "\n",
    "kaist_gt, kaist_recon, lams = load_KAIST_recon_and_gt('data/scene03_recon.mat', 'data/scene03.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_result = comp.hyperColorizationWrapper(np.sum(kaist_gt, axis=0, keepdims=True), kaist_gt, lams, sd, 0.03, False)\n",
    "rgb_gt = vis.draw_hpim(hc_result, lams, draw=True, method= '1931')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lams, kaist_gt[:, 641, 434], label='GT', color='black', linewidth = '2.4')\n",
    "plt.plot(lams, hc_result[:, 641, 434], label='HyperColorization')\n",
    "plt.plot(lams, kaist_recon[:, 641, 434], label='Choi el al.')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octopus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
